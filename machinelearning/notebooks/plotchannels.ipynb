{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/afs/cern.ch/user/m/mrapelli/private/machinelearning/try.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c78706c75732e6365726e2e6368222c2275736572223a226d726170656c6c69227d/afs/cern.ch/user/m/mrapelli/private/machinelearning/try.ipynb#ch0000001vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c78706c75732e6365726e2e6368222c2275736572223a226d726170656c6c69227d/afs/cern.ch/user/m/mrapelli/private/machinelearning/try.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# x axis values \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c78706c75732e6365726e2e6368222c2275736572223a226d726170656c6c69227d/afs/cern.ch/user/m/mrapelli/private/machinelearning/try.ipynb#ch0000001vscode-remote?line=3'>4</a>\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m] \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Data loading and pre-processing:\n",
    "data_dir = '/afs/cern.ch/user/m/mrapelli/private/filldata'\n",
    "#merged_data = pd.DataFrame()\n",
    "\n",
    "for filename in sorted(os.listdir(data_dir), reverse=True):\n",
    "    if not filename.startswith(\"Data_Scaler\"): continue\n",
    "    print(filename)\n",
    "    dataset = pd.read_csv(os.path.join(data_dir, filename), sep=',')\n",
    "    dataset = dataset.drop(columns=['ms','orb','d0','d1','d2','xs','dc01','dc02','dc12','ldc01','ldc02','ldc12'])\n",
    "    print (dataset.shape)\n",
    "    dataset.columns = [filename[:19],'Timestamp','Ch', 's0', 's1', 's2']\n",
    "    dataset = dataset.set_index('Timestamp')\n",
    "    dataset.index = pd.DatetimeIndex(dataset.index).round(freq='1s')\n",
    "    #dataset.index = pd.to_datetime(dataset.index)\n",
    "    #dataset.columns[1] = pd.datetime.strptime(dataset.columns[1], \"%X\")\n",
    "    print(dataset.head())    \n",
    "    #print(dataset.index)\n",
    "    print(dataset.index.shape)\n",
    "    #print(type(dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and pre-processing:\n",
    "dataset_train = pd.read_csv(os.path.join(data_dir, 'Data_Scaler_20180510.csv'), sep=',',infer_datetime_format=True)\n",
    "dataset_train = dataset_train.drop(columns=['ms','orb','d0','d1','d2','xs','dc01','dc02','dc12','ldc01','ldc02','ldc12'])\n",
    "dataset_train.columns = [filename[:19],'Timestamp','Ch', 's0', 's1', 's2']\n",
    "dataset_train = dataset_train.set_index('Timestamp')\n",
    "#dataset.index = pd.to_datetime(dataset.index)\n",
    "dataset_train.index = pd.DatetimeIndex(dataset_train.index).round(freq='1s')#.round(freq='ms')\n",
    "print(dataset_train.head())\n",
    "    \n",
    "dataset_test = pd.read_csv(os.path.join(data_dir, 'Data_Scaler_20181127.csv'), sep=',',infer_datetime_format=True)\n",
    "dataset_test = dataset_test.drop(columns=['ms','orb','d0','d1','d2','xs','dc01','dc02','dc12','ldc01','ldc02','ldc12'])\n",
    "dataset_test.columns = [filename[:19],'Timestamp','Ch', 's0', 's1', 's2']\n",
    "dataset_test = dataset_test.set_index('Timestamp')\n",
    "#dataset.index = pd.to_datetime(dataset.index)\n",
    "dataset_test.index = pd.DatetimeIndex(dataset_test.index).round(freq='1s')\n",
    "print(dataset_test.head())\n",
    "\n",
    "#dataset_train.plot(figsize = (12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and pre-processing:\n",
    "dataset_test = dataset_test.dropna()\n",
    "dataset_train = dataset_train.dropna()\n",
    "dataset_train[dataset_train.isna().any(axis=1)] \n",
    "dataset_test[dataset_test.isna().any(axis=1)] \n",
    "dataset_train = dataset_train.drop(dataset_train.columns[0], axis=1)\n",
    "dataset_test = dataset_test.drop(dataset_test.columns[0], axis=1)\n",
    "display(dataset_train)\n",
    "display(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot channel by channel\n",
    "for i in range(16):\n",
    "    name = i\n",
    "    df = dataset_train.loc[dataset_train['Ch'] == i]\n",
    "    #print(df)\n",
    "    df = df.drop(df.columns[[0]], axis=1)\n",
    "    df.plot(figsize = (12,6))\n",
    "    plt.savefig(f\"train_{name}.png\")\n",
    "    plt.close()     \n",
    "    \n",
    "    #ax.tick_params(axis=\"x\", labelrotation= 90 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot channel by channel\n",
    "for i in range(16):\n",
    "    name = i\n",
    "    df = dataset_train.loc[dataset_train['Ch'] == i]\n",
    "    #print(df)\n",
    "    df = df.drop(df.columns[[0]], axis=1)\n",
    "    df.plot(figsize = (12,6))\n",
    "    plt.savefig(f\"test_{name}.png\")\n",
    "    plt.close()     \n",
    "    \n",
    "    #ax.tick_params(axis=\"x\", labelrotation= 90 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('my_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3f031363a167fa90731a8536d884cc556796eb9131843269a95abee6e5ae8e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
